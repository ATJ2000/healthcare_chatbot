{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optiml_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abelkmathew/healthcare_chatbot/blob/main/Optiml_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disease Prediction ML Model"
      ],
      "metadata": {
        "id": "BeoYI2uNJBSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "The aim is to classify which disease the patient has, so as to find out which department in the hospital the patient has to be refered to."
      ],
      "metadata": {
        "id": "G3tc98a5JBPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description\n",
        "\n",
        "Our ML model is going to be trained with a dataset obtained from Kaggle containing 4921 disease and 132 symptoms that apply to different disease. The user has to input the first symptom, based on this first symptom the ML model makes a First_Prediction and symptoms related to this first prediction is asked to the user. Based on the input given we can get the Final_Prediction and the user can be reffered to a department in the hospital\n"
      ],
      "metadata": {
        "id": "9ii25gpbJBMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "8JSs2dQVJBGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#IMporting Classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#impporting Files to find out accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "metadata": {
        "id": "-VI-K5gqh7sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset read into Dataframe"
      ],
      "metadata": {
        "id": "TehW47vg067b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    training = pd.read_csv('training.csv')\n",
        "    X = training.iloc[:, :-1]\n",
        "    y = training['prognosis']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
        "    training.head(n=5)"
      ],
      "metadata": {
        "id": "gyDwsncQDhTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Exploration"
      ],
      "metadata": {
        "id": "75HwncU61FDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution graphs (histogram/bar graph) of column data\n",
        "\n",
        "def plotPerColumnDistribution(df1, nGraphShown, nGraphPerRow):\n",
        "    nunique = df1.nunique()\n",
        "    df1 = df1[[col for col in training if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df1.shape\n",
        "    columnNames = list(df1)\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = training.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XtXod8BV5QW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter and density plots\n",
        "\n",
        "def plotScatterMatrix(df1, plotSize, textSize):\n",
        "    df1 = df1.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to training being singular\n",
        "    df1 = df1.dropna('columns')\n",
        "    df1 = df1[[col for col in training if training[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(training)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df1 = df1[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df1, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df1.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7cyJ1_kk5RQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotPerColumnDistribution(training, 10, 5)"
      ],
      "metadata": {
        "id": "Sw8MKNoV5erK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotScatterMatrix(training, 20, 10)"
      ],
      "metadata": {
        "id": "hckqq0NB5exz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for symptom within list of symptoms\n",
        "def check_pattern(dis_list,inp):\n",
        "    import re\n",
        "    pred_list=[]\n",
        "    ptr=0\n",
        "    patt = \"^\" + inp + \"$\"\n",
        "    regexp = re.compile(inp)\n",
        "    for item in dis_list:\n",
        "        # print(f\"comparing {inp} to {item}\")\n",
        "        if regexp.search(item):\n",
        "            pred_list.append(item)\n",
        "            # return 1,item\n",
        "    if(len(pred_list)>0):\n",
        "        return 1,pred_list\n",
        "    else:\n",
        "        return ptr,item"
      ],
      "metadata": {
        "id": "T-6Zw8vAC9-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MdWI13aoCP6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "caKgD2daCQIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Accuracy"
      ],
      "metadata": {
        "id": "RwtsMR5D1cfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V2HfC_ZN1h_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "82kqHyS31iCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Output"
      ],
      "metadata": {
        "id": "ttCcVi0I1R9t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkiX2cZura_V"
      },
      "source": [
        "**To build the precision of the model, we utilized three distinctive algorithms which are as per the following**\n",
        "* Decision Tree algorithm\n",
        "* Random Forest algorithm\n",
        "* KNearestNeighbour algorithm\n",
        "* Naive Bayes algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Algorithm"
      ],
      "metadata": {
        "id": "hbAf4_WU7Z9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = DecisionTreeClassifier()\n",
        "rf_clf.fit(X_train.values, y_train)\n",
        "list1=training.columns.tolist()\n",
        "print(\"Enter the symptom you are experiencing  \\n\\t\\t\\t\\t\\t\\t\",end=\"->\")\n",
        "disease_input = input(\"\")\n",
        "conf,cnf_dis=check_pattern(list1,disease_input)\n",
        "if conf==1:\n",
        "  print(\"searches related to input: \")\n",
        "  for num,it in enumerate(cnf_dis):\n",
        "    print(num,\")\",it)\n",
        "  if num!=0:\n",
        "    print(f\"Select the one you meant (0 - {num}):  \", end=\"\")\n",
        "    conf_inp = int(input(\"\"))\n",
        "  else:\n",
        "    conf_inp=0\n",
        "  disease_input=cnf_dis[conf_inp]\n",
        "symptoms_first=[]\n",
        "symptoms_first.append(disease_input)\n",
        "first=rf_clf.predict(symptoms_first)\n",
        "reduced_data = training.groupby(training['prognosis']).max()\n",
        "red_cols = reduced_data.columns\n",
        "symptoms_given = red_cols[reduced_data.loc[first].values[0].nonzero()]\n",
        "symptoms_given=symptoms_given.tolist()\n",
        "if (disease_input in symptoms_given):\n",
        "  symptoms_given.remove(disease_input)\n",
        "print(symptoms_given)\n",
        "\n",
        "symptoms_exp=[]\n",
        "for syms in list(symptoms_given):\n",
        "  inp=\"\"\n",
        "  print(syms,\"? : \",end='')\n",
        "  while True:\n",
        "    inp=input(\"\")\n",
        "    if(inp==\"yes\" or inp==\"no\"):\n",
        "      break\n",
        "    else:\n",
        "      print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
        "  if(inp==\"yes\"):\n",
        "    symptoms_exp.append(syms)\n",
        "symptoms_exp.append(disease_input)\n",
        "print(symptoms_exp)\n",
        "second_prediction=rf_clf.predict(symptoms_exp)\n",
        "print(second_prediction[0])\n",
        "\n",
        "with open('DisDeptClassification.csv',newline='') as csvfile:\n",
        "                    data=csv.DictReader(csvfile)\n",
        "                    for row in data:\n",
        "                        if (row['Disease']==second_prediction[0]):\n",
        "                            dept=row['Department']\n",
        "                            print(dept)"
      ],
      "metadata": {
        "id": "c3vS5IOhVwpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "f78902d2-9d98-42a0-d566-4dd8296a456d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the symptom you are experiencing  \n",
            "\t\t\t\t\t\t->cold\n",
            "searches related to input: \n",
            "0 ) cold_hands_and_feets\n",
            "['cold_hands_and_feets']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-79463993d162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msymptoms_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisease_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymptoms_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymptoms_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mreduced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prognosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mred_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             if issparse(X) and (\n\u001b[1;32m    435\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'cold_hands_and_feets'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Algorithm"
      ],
      "metadata": {
        "id": "SfAIgAye7P9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        " rf_clf=RandomForestClassifier()\n",
        " rf_clf.fit(X_train.values, y_train)\n",
        "print(\"Enter the symptom you are experiencing  \\n\\t\\t\\t\\t\\t\\t\",end=\"->\")\n",
        "disease_input = input(\"\")\n",
        "conf,cnf_dis=check_pattern(list1,disease_input)\n",
        "if conf==1:\n",
        "  print(\"searches related to input: \")\n",
        "  for num,it in enumerate(cnf_dis):\n",
        "    print(num,\")\",it)\n",
        "  if num!=0:\n",
        "    print(f\"Select the one you meant (0 - {num}):  \", end=\"\")\n",
        "    conf_inp = int(input(\"\"))\n",
        "  else:\n",
        "    conf_inp=0\n",
        "  disease_input=cnf_dis[conf_inp]\n",
        "symptoms_first=[]\n",
        "symptoms_first.append(disease_input)\n",
        "first=rf_clf.predict([input_vector])\n",
        "reduced_data = training.groupby(training['prognosis']).max()\n",
        "red_cols = reduced_data.columns\n",
        "symptoms_given = red_cols[reduced_data.loc[first].values[0].nonzero()]\n",
        "symptoms_given=symptoms_given.tolist()\n",
        "if (disease_input in symptoms_given):\n",
        "  symptoms_given.remove(disease_input)\n",
        "print(symptoms_given)\n",
        "\n",
        "symptoms_exp=[]\n",
        "for syms in list(symptoms_given):\n",
        "  inp=\"\"\n",
        "  print(syms,\"? : \",end='')\n",
        "  while True:\n",
        "    inp=input(\"\")\n",
        "    if(inp==\"yes\" or inp==\"no\"):\n",
        "      break\n",
        "    else:\n",
        "      print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
        "  if(inp==\"yes\"):\n",
        "    symptoms_exp.append(syms)\n",
        "symptoms_exp.append(disease_input)\n",
        "print(symptoms_exp)\n",
        "second_prediction=rf_clf.predict([input_vector])\n",
        "print(second_prediction[0])\n",
        "\n",
        "with open('DisDeptClassification.csv',newline='') as csvfile:\n",
        "                    data=csv.DictReader(csvfile)\n",
        "                    for row in data:\n",
        "                        if (row['Disease']==second_prediction[0]):\n",
        "                            dept=row['Department']\n",
        "                            print(dept)"
      ],
      "metadata": {
        "id": "4G2A0UaE7O7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN Algorithm"
      ],
      "metadata": {
        "id": "YiBcg1LQEyK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf=KNeighborsClassifier()\n",
        "rf_clf.fit(X_train.values, y_train)\n",
        "print(\"Enter the symptom you are experiencing  \\n\\t\\t\\t\\t\\t\\t\",end=\"->\")\n",
        "disease_input = input(\"\")\n",
        "conf,cnf_dis=check_pattern(list1,disease_input)\n",
        "if conf==1:\n",
        "  print(\"searches related to input: \")\n",
        "  for num,it in enumerate(cnf_dis):\n",
        "    print(num,\")\",it)\n",
        "  if num!=0:\n",
        "    print(f\"Select the one you meant (0 - {num}):  \", end=\"\")\n",
        "    conf_inp = int(input(\"\"))\n",
        "  else:\n",
        "    conf_inp=0\n",
        "  disease_input=cnf_dis[conf_inp]\n",
        "symptoms_first=[]\n",
        "symptoms_first.append(disease_input)\n",
        "first=rf_clf.predict([input_vector])\n",
        "reduced_data = training.groupby(training['prognosis']).max()\n",
        "red_cols = reduced_data.columns\n",
        "symptoms_given = red_cols[reduced_data.loc[first].values[0].nonzero()]\n",
        "symptoms_given=symptoms_given.tolist()\n",
        "if (disease_input in symptoms_given):\n",
        "  symptoms_given.remove(disease_input)\n",
        "print(symptoms_given)\n",
        "\n",
        "symptoms_exp=[]\n",
        "for syms in list(symptoms_given):\n",
        "  inp=\"\"\n",
        "  print(syms,\"? : \",end='')\n",
        "  while True:\n",
        "    inp=input(\"\")\n",
        "    if(inp==\"yes\" or inp==\"no\"):\n",
        "      break\n",
        "    else:\n",
        "      print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
        "  if(inp==\"yes\"):\n",
        "    symptoms_exp.append(syms)\n",
        "symptoms_exp.append(disease_input)\n",
        "print(symptoms_exp)\n",
        "second_prediction=rf_clf.predict([input_vector])\n",
        "print(second_prediction[0])\n",
        "\n",
        "with open('DisDeptClassification.csv',newline='') as csvfile:\n",
        "                    data=csv.DictReader(csvfile)\n",
        "                    for row in data:\n",
        "                        if (row['Disease']==second_prediction[0]):\n",
        "                            dept=row['Department']\n",
        "                            print(dept)"
      ],
      "metadata": {
        "id": "43ExA0cTEySc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes Algorithm"
      ],
      "metadata": {
        "id": "FGGvK9R4Eymc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_clf=GaussianNB()\n",
        "rf_clf.fit(X_train.values, y_train)\n",
        "print(\"Enter the symptom you are experiencing  \\n\\t\\t\\t\\t\\t\\t\",end=\"->\")\n",
        "disease_input = input(\"\")\n",
        "conf,cnf_dis=check_pattern(list1,disease_input)\n",
        "if conf==1:\n",
        "  print(\"searches related to input: \")\n",
        "  for num,it in enumerate(cnf_dis):\n",
        "    print(num,\")\",it)\n",
        "  if num!=0:\n",
        "    print(f\"Select the one you meant (0 - {num}):  \", end=\"\")\n",
        "    conf_inp = int(input(\"\"))\n",
        "  else:\n",
        "    conf_inp=0\n",
        "  disease_input=cnf_dis[conf_inp]\n",
        "symptoms_first=[]\n",
        "symptoms_first.append(disease_input)\n",
        "first=rf_clf.predict([input_vector])\n",
        "reduced_data = training.groupby(training['prognosis']).max()\n",
        "red_cols = reduced_data.columns\n",
        "symptoms_given = red_cols[reduced_data.loc[first].values[0].nonzero()]\n",
        "symptoms_given=symptoms_given.tolist()\n",
        "if (disease_input in symptoms_given):\n",
        "  symptoms_given.remove(disease_input)\n",
        "print(symptoms_given)\n",
        "\n",
        "symptoms_exp=[]\n",
        "for syms in list(symptoms_given):\n",
        "  inp=\"\"\n",
        "  print(syms,\"? : \",end='')\n",
        "  while True:\n",
        "    inp=input(\"\")\n",
        "    if(inp==\"yes\" or inp==\"no\"):\n",
        "      break\n",
        "    else:\n",
        "      print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
        "  if(inp==\"yes\"):\n",
        "    symptoms_exp.append(syms)\n",
        "symptoms_exp.append(disease_input)\n",
        "print(symptoms_exp)\n",
        "second_prediction=rf_clf.predict([input_vector])\n",
        "print(second_prediction[0])\n",
        "\n",
        "with open('DisDeptClassification.csv',newline='') as csvfile:\n",
        "                    data=csv.DictReader(csvfile)\n",
        "                    for row in data:\n",
        "                        if (row['Disease']==second_prediction[0]):\n",
        "                            dept=row['Department']\n",
        "                            print(dept)"
      ],
      "metadata": {
        "id": "mbBP0s7PEyy0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}